{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy_transformers\n",
        "!pip install -U spacy\n",
        "!pip install spacy==3.6.0"
      ],
      "metadata": {
        "id": "-Oe3h1QXuFWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm\n",
        "import json"
      ],
      "metadata": {
        "id": "YoK-Jblausrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spacy.__version__"
      ],
      "metadata": {
        "id": "ut89rhaOvCTO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e6fc0a21-f85b-4252-c336-abb0237b7f7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.6.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "LFyDAxdGvKpH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0c6e99b-bf14-4434-b237-17b886dd8832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Nov 22 17:14:34 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8    12W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/laxmimerit/CV-Parsing-using-Spacy-3.git"
      ],
      "metadata": {
        "id": "2_OKc8MYvW7A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "297be7f0-0a9e-41e0-f0f5-15fe28fe0a28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CV-Parsing-using-Spacy-3'...\n",
            "remote: Enumerating objects: 82, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 82 (delta 14), reused 74 (delta 14), pack-reused 6\u001b[K\n",
            "Receiving objects: 100% (82/82), 5.62 MiB | 9.49 MiB/s, done.\n",
            "Resolving deltas: 100% (14/14), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_data = json.load(open('/content/CV-Parsing-using-Spacy-3/data/training/train_data.json','r'))"
      ],
      "metadata": {
        "id": "qEQk2FbixSMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(cv_data)"
      ],
      "metadata": {
        "id": "--wr0Y-K1dhO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e93467d5-b579-43ae-dcf4-3669bd8edf36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy init fill-config /content/CV-Parsing-using-Spacy-3/data/training/base_config.cfg /content/CV-Parsing-using-Spacy-3/data/training/config.cfg\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yGf8wt_1d5Q",
        "outputId": "271bd323-342b-4ebc-9f28-1cdcd7da14f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-22 18:11:52.554040: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-22 18:11:52.554091: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-22 18:11:52.554133: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-22 18:11:53.679452: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "/content/CV-Parsing-using-Spacy-3/data/training/config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n",
            "2023-11-22 18:12:00.334471: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-22 18:12:00.334531: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-22 18:12:00.334574: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-22 18:12:01.983432: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.6.0) (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.13)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cv_data"
      ],
      "metadata": {
        "id": "H6MRpH1U1eOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_spacy_doc(file, data):\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    db = DocBin()\n",
        "\n",
        "    for text, annot in tqdm(data):\n",
        "        doc = nlp(text)\n",
        "        entities = annot['entities']\n",
        "\n",
        "        ents = []\n",
        "        entity_indices = set()\n",
        "\n",
        "        for start, end, label in entities:\n",
        "            skip_entity = False\n",
        "            for idx in range(start, end):\n",
        "                if idx in entity_indices:\n",
        "                    skip_entity = True\n",
        "                    break\n",
        "\n",
        "            if skip_entity:\n",
        "                continue\n",
        "\n",
        "            entity_indices.update(range(start, end))\n",
        "\n",
        "            try:\n",
        "                span = doc.char_span(start, end, label=label, alignment_mode='strict')\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "            if span is None:\n",
        "                err_data = f\"{[start, end]}    {text}\\n\"\n",
        "                file.write(err_data)\n",
        "            else:\n",
        "                ents.append(span)\n",
        "\n",
        "        try:\n",
        "            doc.ents = ents\n",
        "            db.add(doc)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    return db\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NWUOH-Bh1e0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train,test = train_test_split(cv_data,test_size=0.3)"
      ],
      "metadata": {
        "id": "JA5L-Ttz9AzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train), len(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKePkBcZ93Fg",
        "outputId": "4f9e93c6-725a-4847-a4c3-26caed1d4e76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(140, 60)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('error.txt','w')\n",
        "\n",
        "db = get_spacy_doc(file, train)\n",
        "db.to_disk('train_data.spacy')\n",
        "\n",
        "db = get_spacy_doc(file, test)\n",
        "db.to_disk('test_data.spacy')\n",
        "\n",
        "\n",
        "file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhYdSC_A99aJ",
        "outputId": "99dfcc65-9c62-4aef-dde6-1be02af8432b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 140/140 [00:14<00:00,  9.45it/s]\n",
            "100%|██████████| 60/60 [00:09<00:00,  6.46it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(db.tokens)\n"
      ],
      "metadata": {
        "id": "4cTxsKBqPP3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy train /content/CV-Parsing-using-Spacy-3/data/training/config.cfg --output ./output --paths.train ./train_data.spacy --paths.dev ./test_data.spacy --gpu-id 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyQ9iGa7R2JM",
        "outputId": "8ac44df1-3570-4a4a-d9d2-c36a77a37564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-22 18:48:44.749320: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-22 18:48:44.749388: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-22 18:48:44.749425: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-22 18:48:46.480586: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2023-11-22 18:48:51,152] [INFO] Set up nlp object from config\n",
            "[2023-11-22 18:48:51,169] [INFO] Pipeline: ['transformer', 'ner']\n",
            "[2023-11-22 18:48:51,173] [INFO] Created vocabulary\n",
            "[2023-11-22 18:48:51,173] [INFO] Finished initializing nlp object\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[2023-11-22 18:48:59,485] [INFO] Initialized pipeline components: ['transformer', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  -------------  --------  ------  ------  ------  ------\n",
            "  0       0        4918.26    733.96    0.12    0.07    0.47    0.00\n",
            "  2     200      227642.49  47554.79   11.07   40.15    6.42    0.11\n",
            "  5     400       68097.96  20771.12   36.62   45.13   30.81    0.37\n",
            "  8     600        6518.13  17828.54   47.14   47.62   46.67    0.47\n",
            " 11     800       25581.72  17127.68   52.48   51.22   53.79    0.52\n",
            " 14    1000       16422.87  16185.48   54.23   50.40   58.69    0.54\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "output/model-last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MODEL TESTING\n"
      ],
      "metadata": {
        "id": "N6_UB4pIaWtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('/content/output/model-best')"
      ],
      "metadata": {
        "id": "NRyLbzpPacwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp('my name is Laxmi Kant Tiwari. I worked at Microsoft.I have 10 years expereince')\n",
        "for ent in doc.ents:\n",
        "  print(ent.text,\"   ->>>>>\", ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s501h7yRaqG7",
        "outputId": "d88a8219-205c-4892-cd26-f575d7c880af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Laxmi Kant    ->>>>> Name\n",
            "Microsoft    ->>>>> Companies worked at\n",
            "10 years    ->>>>> Years of Experience\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF"
      ],
      "metadata": {
        "id": "8DW4AAH-cEYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, fitz"
      ],
      "metadata": {
        "id": "zFdbPtitcTm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fname='/content/CV-Parsing-using-Spacy-3/data/test/Alice Clark CV.pdf'\n",
        "doc= fitz.open(fname)"
      ],
      "metadata": {
        "id": "_i21nalCcW7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \" \"\n",
        "for page in doc:\n",
        "  text = text + str(page.get_text())\n"
      ],
      "metadata": {
        "id": "8ScpUL_vcsIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = text.strip()"
      ],
      "metadata": {
        "id": "JVE9d9e6c2FB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'  '.join(text.split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "pAxelHUYd3ic",
        "outputId": "e5d81752-8a09-44e2-9dbb-3c1ba25f515c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Alice  Clark  AI  /  Machine  Learning  Delhi,  India  Email  me  on  Indeed  •  20+  years  of  experience  in  data  handling,  design,  and  development  •  Data  Warehouse:  Data  analysis,  star/snow  flake  scema  data  modelling  and  design  specific  to  data  warehousing  and  business  intelligence  •  Database:  Experience  in  database  designing,  scalability,  back-up  and  recovery,  writing  and  optimizing  SQL  code  and  Stored  Procedures,  creating  functions,  views,  triggers  and  indexes.  Cloud  platform:  Worked  on  Microsoft  Azure  cloud  services  like  Document  DB,  SQL  Azure,  Stream  Analytics,  Event  hub,  Power  BI,  Web  Job,  Web  App,  Power  BI,  Azure  data  lake  analytics(U-SQL)  Willing  to  relocate  anywhere  WORK  EXPERIENCE  Software  Engineer  Microsoft  –  Bangalore,  Karnataka  January  2000  to  Present  1.  Microsoft  Rewards  Live  dashboards:  Description:  -  Microsoft  rewards  is  loyalty  program  that  rewards  Users  for  browsing  and  shopping  online.  Microsoft  Rewards  members  can  earn  points  when  searching  with  Bing,  browsing  with  Microsoft  Edge  and  making  purchases  at  the  Xbox  Store,  the  Windows  Store  and  the  Microsoft  Store.  Plus,  user  can  pick  up  bonus  points  for  taking  daily  quizzes  and  tours  on  the  Microsoft  rewards  website.  Rewards  live  dashboards  gives  a  live  picture  of  usage  world-wide  and  by  markets  like  US,  Canada,  Australia,  new  user  registration  count,  top/bottom  performing  rewards  offers,  orders  stats  and  weekly  trends  of  user  activities,  orders  and  new  user  registrations.  the  PBI  tiles  gets  refreshed  in  different  frequencies  starting  from  5  seconds  to  30  minutes.  Technology/Tools  used  EDUCATION  Indian  Institute  of  Technology  –  Mumbai  2001  SKILLS  Machine  Learning,  Natural  Language  Processing,  and  Big  Data  Handling  ADDITIONAL  INFORMATION  Professional  Skills  •  Excellent  analytical,  problem  solving,  communication,  knowledge  transfer  and  interpersonal  skills  with  ability  to  interact  with  individuals  at  all  the  levels  •  Quick  learner  and  maintains  cordial  relationship  with  project  manager  and  team  members  and  good  performer  both  in  team  and  independent  job  environments  •  Positive  attitude  towards  superiors  &amp;  peers  •  Supervised  junior  developers  throughout  project  lifecycle  and  provided  technical  assistance'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(text)\n",
        "for ent in doc.ents:\n",
        "  print(ent.text,\"   ->>>>>\", ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qdHMAa7eLNN",
        "outputId": "4ec3f084-2162-4585-c0f2-4ae13fc5651e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alice Clark    ->>>>> Name\n",
            "AI / Machine Learning    ->>>>> Designation\n",
            "Delhi    ->>>>> Location\n",
            "20+    ->>>>> Years of Experience\n",
            "Software Engineer    ->>>>> Designation\n",
            "Indian Institute of Technology    ->>>>> College Name\n",
            "2001    ->>>>> Graduation Year\n"
          ]
        }
      ]
    }
  ]
}